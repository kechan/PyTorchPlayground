{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Discrete Logistic Equantion with PyTorch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"YRo1Jby6M6P0","colab_type":"text"},"cell_type":"markdown","source":["# Discrete Logistic Equation with PyTorch. "]},{"metadata":{"id":"61iEcfdmNKQv","colab_type":"text"},"cell_type":"markdown","source":["This notebook contains a toy experiment of using PyTorch to investigate non-linear dynamics. The simplest example is the Discrete Logistic Equation (not the same as Logistic function). \n","\n","---\n","\n","For a scalar $x$, we look at how it evolves over time discretely: \n","\n","$x_{n+1} = a x_{n} (1 - x_n)$ with initial value $x_o$.\n","\n","* This is the simplist plausible growth model constrained by a finite resource (e.g. bacteria in a petri dish)\n","\n","* $a$ is the \"tuning knob\" that govern qualitatively behavior of $x_n$ over time. \n","\n","* We will use pytorch to evolve an ensemble of x chosen randomly between 0.0 and 1.0, which will be the initial conditions $x_o$s.\n","\n","* We will focus on how \"well\" $x$ is doing by looking at the mean over all histories (entire ensemble).\n","\n","* We will use PyTorch  to maximize this measure of how $x$ does by tuning $a$.\n","\n","If the code is right and pyTorch is working as I understood, $a=3.0013$ seems like optimal (or a local one). Beware that there's lot of fluctuations if $a$ is close to 4.0, when chaos set in."]},{"metadata":{"id":"2zoMGZcSCnT4","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","# dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","dev = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tsoGN64QC_jE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e2ea35c-e458-4066-ef55-35f4990bcfc1","executionInfo":{"status":"ok","timestamp":1548901380201,"user_tz":300,"elapsed":1200,"user":{"displayName":"Kelvin Chan","photoUrl":"","userId":"01396511609092383239"}}},"cell_type":"code","source":["a = torch.tensor(2.5, dtype=torch.double).to(dev)\n","a.requires_grad_()"],"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.5000, dtype=torch.float64, requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":77}]},{"metadata":{"id":"X1NpvbR1DXUR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1717},"outputId":"6e85ddc0-f47f-423b-a610-4e3c50591e54","executionInfo":{"status":"ok","timestamp":1548901414840,"user_tz":300,"elapsed":31111,"user":{"displayName":"Kelvin Chan","photoUrl":"","userId":"01396511609092383239"}}},"cell_type":"code","source":["epochs = 100\n","lr = 0.05\n","n_ensemble = 10000.0\n","n_t = 1000\n","\n","for epoch in range(epochs):\n","  \n","  x = torch.rand(int(n_ensemble), dtype=torch.double).to(dev)    # initialize an ensemble of x\n","  mean_x = torch.tensor(0.0, dtype=torch.double).to(dev)         # initialize the quantity we want to maximize\n","  for i in range(n_t):\n","    x = a * x * (1.0 - x)     # x evolving according to discrete logistic equation over time.\n","    mean_x += torch.sum(x)      \n","  mean_x /= (n_ensemble * n_t)  # mean(x) over history and ensemble #.\n","  \n","  mean_x.backward()\n","  with torch.no_grad():\n","    a += a.grad * lr \n","    a.grad.zero_()\n","    print(a)"],"execution_count":78,"outputs":[{"output_type":"stream","text":["tensor(2.5080, dtype=torch.float64, requires_grad=True)\n","tensor(2.5160, dtype=torch.float64, requires_grad=True)\n","tensor(2.5239, dtype=torch.float64, requires_grad=True)\n","tensor(2.5317, dtype=torch.float64, requires_grad=True)\n","tensor(2.5395, dtype=torch.float64, requires_grad=True)\n","tensor(2.5473, dtype=torch.float64, requires_grad=True)\n","tensor(2.5550, dtype=torch.float64, requires_grad=True)\n","tensor(2.5627, dtype=torch.float64, requires_grad=True)\n","tensor(2.5703, dtype=torch.float64, requires_grad=True)\n","tensor(2.5779, dtype=torch.float64, requires_grad=True)\n","tensor(2.5854, dtype=torch.float64, requires_grad=True)\n","tensor(2.5929, dtype=torch.float64, requires_grad=True)\n","tensor(2.6003, dtype=torch.float64, requires_grad=True)\n","tensor(2.6077, dtype=torch.float64, requires_grad=True)\n","tensor(2.6151, dtype=torch.float64, requires_grad=True)\n","tensor(2.6224, dtype=torch.float64, requires_grad=True)\n","tensor(2.6297, dtype=torch.float64, requires_grad=True)\n","tensor(2.6369, dtype=torch.float64, requires_grad=True)\n","tensor(2.6441, dtype=torch.float64, requires_grad=True)\n","tensor(2.6513, dtype=torch.float64, requires_grad=True)\n","tensor(2.6584, dtype=torch.float64, requires_grad=True)\n","tensor(2.6655, dtype=torch.float64, requires_grad=True)\n","tensor(2.6725, dtype=torch.float64, requires_grad=True)\n","tensor(2.6795, dtype=torch.float64, requires_grad=True)\n","tensor(2.6865, dtype=torch.float64, requires_grad=True)\n","tensor(2.6934, dtype=torch.float64, requires_grad=True)\n","tensor(2.7003, dtype=torch.float64, requires_grad=True)\n","tensor(2.7072, dtype=torch.float64, requires_grad=True)\n","tensor(2.7140, dtype=torch.float64, requires_grad=True)\n","tensor(2.7208, dtype=torch.float64, requires_grad=True)\n","tensor(2.7275, dtype=torch.float64, requires_grad=True)\n","tensor(2.7343, dtype=torch.float64, requires_grad=True)\n","tensor(2.7410, dtype=torch.float64, requires_grad=True)\n","tensor(2.7476, dtype=torch.float64, requires_grad=True)\n","tensor(2.7542, dtype=torch.float64, requires_grad=True)\n","tensor(2.7608, dtype=torch.float64, requires_grad=True)\n","tensor(2.7674, dtype=torch.float64, requires_grad=True)\n","tensor(2.7739, dtype=torch.float64, requires_grad=True)\n","tensor(2.7804, dtype=torch.float64, requires_grad=True)\n","tensor(2.7869, dtype=torch.float64, requires_grad=True)\n","tensor(2.7934, dtype=torch.float64, requires_grad=True)\n","tensor(2.7998, dtype=torch.float64, requires_grad=True)\n","tensor(2.8061, dtype=torch.float64, requires_grad=True)\n","tensor(2.8125, dtype=torch.float64, requires_grad=True)\n","tensor(2.8188, dtype=torch.float64, requires_grad=True)\n","tensor(2.8251, dtype=torch.float64, requires_grad=True)\n","tensor(2.8314, dtype=torch.float64, requires_grad=True)\n","tensor(2.8376, dtype=torch.float64, requires_grad=True)\n","tensor(2.8438, dtype=torch.float64, requires_grad=True)\n","tensor(2.8500, dtype=torch.float64, requires_grad=True)\n","tensor(2.8562, dtype=torch.float64, requires_grad=True)\n","tensor(2.8623, dtype=torch.float64, requires_grad=True)\n","tensor(2.8684, dtype=torch.float64, requires_grad=True)\n","tensor(2.8745, dtype=torch.float64, requires_grad=True)\n","tensor(2.8805, dtype=torch.float64, requires_grad=True)\n","tensor(2.8865, dtype=torch.float64, requires_grad=True)\n","tensor(2.8925, dtype=torch.float64, requires_grad=True)\n","tensor(2.8985, dtype=torch.float64, requires_grad=True)\n","tensor(2.9045, dtype=torch.float64, requires_grad=True)\n","tensor(2.9104, dtype=torch.float64, requires_grad=True)\n","tensor(2.9163, dtype=torch.float64, requires_grad=True)\n","tensor(2.9221, dtype=torch.float64, requires_grad=True)\n","tensor(2.9280, dtype=torch.float64, requires_grad=True)\n","tensor(2.9338, dtype=torch.float64, requires_grad=True)\n","tensor(2.9396, dtype=torch.float64, requires_grad=True)\n","tensor(2.9454, dtype=torch.float64, requires_grad=True)\n","tensor(2.9511, dtype=torch.float64, requires_grad=True)\n","tensor(2.9568, dtype=torch.float64, requires_grad=True)\n","tensor(2.9625, dtype=torch.float64, requires_grad=True)\n","tensor(2.9681, dtype=torch.float64, requires_grad=True)\n","tensor(2.9738, dtype=torch.float64, requires_grad=True)\n","tensor(2.9793, dtype=torch.float64, requires_grad=True)\n","tensor(2.9849, dtype=torch.float64, requires_grad=True)\n","tensor(2.9903, dtype=torch.float64, requires_grad=True)\n","tensor(2.9956, dtype=torch.float64, requires_grad=True)\n","tensor(3.0005, dtype=torch.float64, requires_grad=True)\n","tensor(3.0015, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n","tensor(3.0013, dtype=torch.float64, requires_grad=True)\n"],"name":"stdout"}]},{"metadata":{"id":"jS0iFiO7Gf2C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f0f957db-6f99-4a64-ec5e-d29067e5c358","executionInfo":{"status":"ok","timestamp":1548896097522,"user_tz":300,"elapsed":1266,"user":{"displayName":"Kelvin Chan","photoUrl":"","userId":"01396511609092383239"}}},"cell_type":"code","source":["torch.rand(int(n_ensemble))"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.4440, 0.8260, 0.2146,  ..., 0.7653, 0.5723, 0.7130])"]},"metadata":{"tags":[]},"execution_count":43}]},{"metadata":{"id":"jIGS0SuHLLsb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7b34b7e7-9179-49b1-af36-cd3117a89983","executionInfo":{"status":"ok","timestamp":1548902596540,"user_tz":300,"elapsed":566,"user":{"displayName":"Kelvin Chan","photoUrl":"","userId":"01396511609092383239"}}},"cell_type":"code","source":["a"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.0013, dtype=torch.float64, requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":79}]},{"metadata":{"id":"Cg06kyZ8bE47","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}